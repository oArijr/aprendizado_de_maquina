# -*- coding: utf-8 -*-
"""TRABALHO 3 - PARTE 2: Algoritmo Árvores de Decisão.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P7VwNUgFw7GtafoFWR0mVoAsqIc9F__p

# PARTE 2: Algoritmo Árvores de Decisão

Nesta segunda parte do Trabalho você irá aplicar os algoritmos de Árvore de Decisão e de Floresta Aleatória na base de dados de risco de crédito discutida em aula. Para isso você deve primeiramente importar as bibliotecas necessárias.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.preprocessing import LabelEncoder

"""# 1 - Importação dos dados Pré-Processados

a) importe o arquivo salvo como 'risco_credito.pkl'
"""
import pickle
with open('risco_credito.pkl', 'rb') as f:
  X_risco_credito, y_risco_credito = pickle.load(f)

atributos = ["História do Crédito", "Dívida", "Garantias", "Renda Anual"]
X_risco_credito = pd.DataFrame(X_risco_credito, columns=atributos)

x_encoded = X_risco_credito.copy()
label_encoders = {}

for col in x_encoded.columns:
    le = LabelEncoder()
    x_encoded[col] = le.fit_transform(x_encoded[col])
    label_encoders[col] = le

le_y = LabelEncoder()
y_encoded = le_y.fit_transform(y_risco_credito)

print("_" * 80)
"""# 2 - Algoritmo de Árvore de Decisão"""

""" a) importar da biblioteca sklearn o pacote DecisionTreeClassifier"""
from sklearn.tree import DecisionTreeClassifier
"""
 b) Calcule a árvore de decisão, utilizando como critério a entropia.
 Coloque como nome da variável: arvore_risco_credito
"""
arvore_risco_credito = DecisionTreeClassifier(criterion='entropy')
arvore_risco_credito.fit(x_encoded, y_encoded)

"""c) Utilize o feature_importances_ para retornar a importância de cada atributo. Qual possui o maior ganho de informação?"""
feature_importances = arvore_risco_credito.feature_importances_

for nome, importancia in zip(arvore_risco_credito.feature_names_in_, feature_importances):
    print(f"{nome}: {importancia}")

# R: O atributo com maior ganho de informação é a Renda Atual

"""
d) Gere uma visualização da sua árvore de decisão utilizando o pacote tree da biblioteca do sklearn.
OBS: Adicione cores, nomes para os atributos e para as classes.
"""
from sklearn import tree

plt.figure(figsize=(16, 9))
tree.plot_tree(
    arvore_risco_credito,
    feature_names=arvore_risco_credito.feature_names_in_,
    class_names=le_y.classes_,
    filled=True,
    proportion=True,
    fontsize=12
)
plt.show()

"""
e) FAZER A PREVISÃO

Utilize .predict para fazer a previsão realizada no exemplo em sala.

i. história boa, dívida alta, garantia nenhuma, renda > 35

ii. história ruim, dívida alta, garantia adequada, renda < 15
Verifique nos slides se seu resultado está correto!
"""

exemplo_1 = [
    label_encoders['História do Crédito'].transform(['boa'])[0],
    label_encoders['Dívida'].transform(['alta'])[0],
    label_encoders['Garantias'].transform(['nenhuma'])[0],
    label_encoders['Renda Anual'].transform(['acima_35'])[0]
]

exemplo_2 = [
    label_encoders['História do Crédito'].transform(['ruim'])[0],
    label_encoders['Dívida'].transform(['alta'])[0],
    label_encoders['Garantias'].transform(['adequada'])[0],
    label_encoders['Renda Anual'].transform(['0_15'])[0]
]

exemplos = [exemplo_1, exemplo_2]

previsoes = le_y.inverse_transform(arvore_risco_credito.predict(exemplos))

for i, previsao in enumerate(previsoes, start=1):
    print(f"Exemplo {i}: {previsao}")

# Resultado do slide: Exemplo 1 = Baixo, Exemplo 2 = Alto

print("_" * 80)
"""
#3 - Algoritmo de Árvore de Decisão para uma base de dados maior (Credit Data)

Nesta seção você deverá testar o uso da Árvore de Decisão para a Base de Dados Credit Risk Dataset. 
Aqui estaremos analisando os clientes que pagam (classe 0) ou não pagam a dívida (classe 1), a fim do banco conceder empréstimo.
"""
# abrir o arquivo
with open('credit.pkl', 'rb') as f:
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

"""a) Ao abrir o arquivo utilize .shape para verificar o tamanho dos dados de treinamento e de teste

OBS: os dados de treinamento devem ter as seguintes dimenções: x=(1500, 3), y=(1500,); os dados de teste devem ter as seguintes dimenções: x=(500, 3), y=(500,)"""

print(f"Treinamento X= {X_credit_treinamento.shape}")
print(f"Treinamento y= {y_credit_treinamento.shape}")
print(f"Teste X= {X_credit_teste.shape}")
print(f"Teste y= {y_credit_teste.shape}")

"""b) Importe o pacote DecisionTreeClassifier do sklearn para treinar o seu algoritmo de árvore de decisão. Para poder refazer os testes e obter o mesmo resultado utilize o parâmetro random_state = 0."""
# Já está sendo importado
arvore_credit = DecisionTreeClassifier(criterion='entropy', random_state=0)
arvore_credit.fit(X_credit_treinamento, y_credit_treinamento)

"""c) Faça a previsão com os dados de teste. Visualize os dados e verifique se as previsões estão de acordo com os dados de teste (respostas reais)."""
credit_test_predict = arvore_credit.predict(X_credit_teste)

resultado_df = pd.DataFrame({
    'Real': y_credit_teste,
    'Previsto': credit_test_predict
})

print(resultado_df.head(20))

"""d) Agora faça o cálculo da acurácia para calcular a taxa de acerto entre os valores reais (y teste) e as previsões"""
from sklearn.metrics import accuracy_score
credit_accuracy = accuracy_score(y_credit_teste, credit_test_predict) * 100

print(f"Acurácia do credit: {credit_accuracy}%")

"""e) Faça a análise da Matriz de Confusão.

i. Quantos clientes foram classificados corretamente que pagam a dívida?

ii. Quantos clientes foram classificados incorretamente como não pagantes?

iii. Quantos clientes foram classificados corretamente que não pagam?

iv. Quantos clientes foram classificados incorretamente como pagantes?
"""
from sklearn.metrics import confusion_matrix
matriz = confusion_matrix(y_credit_teste, credit_test_predict)

print(matriz)

# i. Foram classificados 430
# ii. Foram classificados 6
# iii. Foram classificados 61
# iv. Foram classificados 3

"""f) Faça um print do parâmetro classification_report entre os dados de teste e as previsões. Explique qual é a relação entre precision e recall nos dados. Como você interpreta esses dados? """
from sklearn.metrics import classification_report

print(classification_report(y_credit_teste, credit_test_predict))

# Uma precision alta indica que o modelo cometeu poucos falsos positivos, ou seja,
# quando prevê que o cliente pagará a dívida, essa previsão geralmente está correta.
# Já um recall alto significa que o modelo cometeu poucos falsos negativos,
# ou seja, conseguiu identificar a maioria dos clientes que realmente pagam.
# No caso da classe 0 (pagantes), o modelo apresentou alta precisão,
# demonstrando boa capacidade de evitar classificar indevidamente como pagante
# alguém que na verdade não pagaria.

"""g) Gere uma visualização da sua árvore de decisão utilizando o pacote tree da biblioteca do sklearn.

OBS 1: Os atributos previsores são = ['income', 'age', 'loan']

OBS 2: Adicione cores, nomes para os atributos e para as classes. Você pode utilizar a função fig.savefig para salvar a árvore em uma imagem .png 
"""
atributos = ['income', 'age', 'loan']
classes = ['pagam', 'não pagam']

plt.figure(figsize=(40, 20))
tree.plot_tree(
    arvore_credit,
    feature_names=atributos,
    class_names=classes,
    filled=True,
    proportion=True,
    rounded=True,
    fontsize=12
)
plt.savefig("arvore_credito.png", dpi=300)
plt.show()

"""
# Algoritmo Random Forest

Nesta seção iremos utilizar o algoritmo Random Forest para a mesma base de crédito (**Credit Risk Dataset**) - arquivo *credit.pkl*.

a) Importe o pacote RandomForestClassifier do sklearn para treinar o seu algoritmo de floresta randomica.
"""
from sklearn.ensemble import RandomForestClassifier

"""
b) Para gerar a classificação você deve adicionar alguns parâmetros:
*   n_estimators=10  --> número de árvores que você irá criar
*   criterion='entropy'
*   random_state = 0
"""
floresta_credit = RandomForestClassifier(
    n_estimators=10,
    criterion='entropy',
    random_state=0
)

floresta_credit.fit(X_credit_treinamento, y_credit_treinamento)

"""
c) Faça a previsão com os dados de teste. Visualize os dados e verifique se as previsões estão de acordo com os dados de teste (respostas reais).
"""
floresta_predict = floresta_credit.predict(X_credit_teste)

resultado_fp = pd.DataFrame({
    'Real': y_credit_teste,
    'Previsto': floresta_predict
})

print(resultado_fp.head(20))

"""
d) Agora faça o cálculo da acurácia para calcular a taxa de acerto entre os valores reais (y teste) e as previsões. O resultado foi melhor do que a árvore de decisão simples?
"""
floresta_accuracy = accuracy_score(y_credit_teste, floresta_predict) * 100
print(f"Acurácia do modelo Random Forest: {floresta_accuracy}%")

# Não, o resultado da árvore simples foi de 98.2% já utilizando a floresta a acuracia chegou a 96.8%.

"""
e) Se o resultado foi inferior, como você poderia resolver isso? Quais foram os resultados obtidos?
"""
floresta_credit_novo = RandomForestClassifier(
    n_estimators=100,
    criterion='entropy',
    random_state=0
)

floresta_credit_novo.fit(X_credit_treinamento, y_credit_treinamento)

floresta_predict_novo = floresta_credit_novo.predict(X_credit_teste)

floresta_accuracy_novo = accuracy_score(y_credit_teste, floresta_predict_novo) * 100
print(f"Nova Acurácia do modelo Random Forest: {floresta_accuracy_novo}%")

# Aumentei a quantidade de árvores para 100 e o resultado igualou a acuracia entre a floresta e uma única árvore, ambas com 98.2% de acurácia.
"""
f) Faça a análise da Matriz de Confusão.
"""
matriz_floresta = confusion_matrix(y_credit_teste, floresta_predict_novo)
print(matriz_floresta)

# 433 classificados corretamente como pagantes.
# 3 classificados incorretamente como pagantes.
# 6 classificados incorretamente como não-pagantes.
# 58 classificados corretamente como não-pagantes.
# O modelo apresentou uma excelente taxa de acerto. O modelo apresentou uma leve tendência a classificar os clientes como pagantes,
# o que pode indicar uma preferência por evitar falsos negativos (deixar de conceder crédito a quem pagaria).

"""
g) Faça um print do parâmetro classification_report entre os dados de teste e as previsões. Explique qual é a relação entre precision e recall nos dados. Como você interpreta esses dados?
"""
print(classification_report(y_credit_teste, floresta_predict_novo))

#   Precision indica a proporção de previsões positivas que estavam corretas. No caso da classe 0 (pagantes) a precisão foi de 99%
#   o que quer dizer que 99% dos clientes previstos como pagantes realmente pagam suas dividas e para a classe 1 (inadimplentes),
#   a precisão foi de 0.95, ou seja, 95% dos clientes previstos como inadimplentes realmente não pagam a dívida.

#   Recall mostra a proporção de casos positivos reais que foram corretamente identificados pelo modelo.
#   Para a classe 0, o recall foi de 99%, indicando que 99% dos pagantes reais foram corretamente detectados.
#   Para a classe 1, o recall foi de 0.91, o que significa que 91% dos inadimplentes reais foram corretamente detectados.

#   Como falei na resposta anterior, o modelo apresentou uma leve tendencia a classificar os inadimplentes como pagantes.
